{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation using ArXiv Research Paper Abstracts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArXiv is an online repository of research papers in various fields of science, technology, engineering, and mathematics (STEM). The abstracts of these papers contain a wealth of information, including summaries of the research questions, methodology, and key findings. This information can be used to train a machine learning model to generate new texts that are similar in style and content to the abstracts.\n",
    "\n",
    "The aim of this project is to develop an ML model that can generate texts based on the abstracts of ArXiv research papers. This model can be used to assist researchers and academics in summarizing their research, generating new ideas, or exploring new directions for their work.\n",
    "\n",
    "The dataset for this project will be obtained from ArXiv, and will consist of a large collection of research paper abstracts. The dataset will be preprocessed to remove any irrelevant information and to ensure that the abstracts are in a consistent format. Then, a range of feature engineering techniques will be applied to extract meaningful features from the abstracts.\n",
    "\n",
    "Next, several machine learning models will be trained on the preprocessed and feature engineered data. The focus will be on generative models such as GPT-2 and GPT-3, which have shown impressive performance in generating high-quality texts. The performance of each model will be evaluated using standard natural language processing metrics, and the best-performing model will be selected for deployment.\n",
    "\n",
    "Finally, the selected model will be integrated into a web-based application that can generate texts in real-time. The application will have an easy-to-use interface and will allow users to specify the domain and topic of interest. The generated texts will be displayed along with an explanation of how they were generated and the ArXiv papers that were used as the basis for the generation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "### 1. [Importing the data](#importing-the-data)\n",
    "\n",
    "1.   [Importing Packages](#importing-packages)\n",
    "2.   [Importing the dataset](#importing-the-dataset)\n",
    "\n",
    "### 2. [Data Pre-Processing](#data-pre-processing)\n",
    "\n",
    "1. [Counting Unique characters](#counting-unique-characters)\n",
    "2. [Character to Integer Mapping](#character-to-integer-mapping)\n",
    "    1. [Visualizing the Character to Integer Mapping](#visualizing-the-character-to-integer-mapping)\n",
    "3. [Preparing the Dataset](#preparing-the-dataset)\n",
    "    1. [Creating sequences](#creating-sequences)\n",
    "    2. [Creating batches of sequences](#creating-batches-of-sequences)\n",
    "    3. [Splitting sequences into Inputs and Targets](#splitting-sequences-into-inputs-and-targets)\n",
    "    4. [Creating the final Dataset](#creating-the-final-dataset)\n",
    "        1. [Shuffling the dataset](#shuffling-the-dataset)\n",
    "        2. [Creating batches for the dataset](#creating-batches-for-the-dataset)\n",
    "\n",
    "### 3. [Model Building](#model-building)\n",
    "1. [Creating the single layer GRU model](#creating-the-single-layer-gru-model)\n",
    "    1. [Building the GRU model](#building-the-gru-model)\n",
    "    2. [Compiling the GRU model](#compiling-the-gru-model)\n",
    "    3. [Setting callbacks for the GRU model](#setting-callbacks-for-the-gru-model)\n",
    "    4. [Training the GRU model](#training-the-gru-model)\n",
    "    5. [Testing the GRU model](#testing-the-gru-model)\n",
    "2. [Creating the single layer LSTM model](#creating-the-single-layer-gru-model)\n",
    "    1. [Building the LSTM model](#building-the-lstm-model)\n",
    "    2. [Compiling the LSTM model](#compiling-the-lstm-model)\n",
    "    3. [Setting callbacks for the LSTM model](#setting-callbacks-for-the-lstm-model)\n",
    "    4. [Training the LSTM model](#training-the-lstm-model)\n",
    "    5. [Testing the LSTM model](#testing-the-lstm-model)\n",
    "3. [Creating the model with GPT2 Transformer](#creating-the-model-with-gpt2-transformer)\n",
    "    1. [Importing packages and pretrained models](#importing-packages-and-pretrained-models)\n",
    "    2. [Loading pre-trained models](#loading-pre-trained-models)\n",
    "    3. [Testing Encoding and Decoding](#testing-encoding-and-decoding)\n",
    "    4. [Testing the GPT2 model](#testing-the-gpt2-model)\n",
    "4. [Creating the model using DistilGPT2 transformer (Transfer Learning)](#creating-the-model-using-distilgpt2-transformer-transfer-learning)\n",
    "    1. [Loading the ArXiv dataset (from HuggingFace Hub)](#loading-the-arxiv-dataset-from-huggingface-hub)\n",
    "    2. [Pre-processing](#pre-processing)\n",
    "    3. [Building the DistilGPT2 model](#building-the-distilgpt2-model)\n",
    "    4. [Compiling the DistilGPT2 model](#compiling-the-distilgpt2-model)\n",
    "    5. [Training the DistilGPT2 model](#training-the-distilgpt2-model)\n",
    "    6. [Testing the DistilGPT2 model](#testing-the-distilgpt2-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\anaconda3\\envs\\virtualenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForCausalLM, AutoTokenizer, AdamWeightDecay, pipeline, create_optimizer\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import DefaultDataCollator\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pio.renderers.default = 'notebook_connected'\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains the total of 64838939 characters\n"
     ]
    }
   ],
   "source": [
    "data = r'arxivData.txt'\n",
    "text = open(data,'rb').read().decode(encoding='utf-8')\n",
    "print('Dataset contains the total of {} characters'.format(len(text)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character to Integer Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "'\\n':   0,\n",
      "'\\r':   1,\n",
      "' ' :   2,\n",
      "'!' :   3,\n",
      "'\"' :   4,\n",
      "'#' :   5,\n",
      "'$' :   6,\n",
      "'%' :   7,\n",
      "'&' :   8,\n",
      "\"'\" :   9,\n",
      "'(' :  10,\n",
      "')' :  11,\n",
      "'*' :  12,\n",
      "'+' :  13,\n",
      "',' :  14,\n",
      "'-' :  15,\n",
      "'.' :  16,\n",
      "'/' :  17,\n",
      "'0' :  18,\n",
      "'1' :  19,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('{:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Character to Integer Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'itle,year\\r\\n\"[{\\'name\\': \\'Ah'---char2int--- [75 86 78 71 14 91 71 67 84  1  0  4 61 93  9 80 67 79 71  9 28  2  9 35\n",
      " 74]\n"
     ]
    }
   ],
   "source": [
    "print('{}---char2int--- {}'.format(repr(text[38:63]), text_as_int[38:63]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We are not doing stemming and lemmatization because we need letters and special characters such as for raised to ^ sign."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We levarage a sliding window approach to train our model. We first set the maximum sequence length to 120 characters. This is done for the purpose of preparing and training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "u\n",
      "t\n",
      "h\n",
      "o\n",
      "r\n",
      ",\n",
      "d\n",
      "a\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of a sentence we want for a single input in characters\n",
    "seq_length = 120\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "#Create training examples\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(10):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating batches of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'author,day,id,link,month,summary,tag,title,year\\r\\n\"[{\\'name\\': \\'Ahmed Osman\\'}, {\\'name\\': \\'Wojciech Samek\\'}]\",1,1802.00209v1,\"'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\"[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1802.00209v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http\"\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'://arxiv.org/pdf/1802.00209v1\\', \\'type\\': \\'application/pdf\\', \\'title\\': \\'pdf\\'}]\",2,\"We propose an architecture for VQA which '\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent a'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ttention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations bet'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'ween several\\nparts of the image and question. Our single model outperforms the first place\\nwinner on the VQA 1.0 dataset,'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "' performs within margin to the current\\nstate-of-the-art ensemble model. We also experiment with replacing attention\\nmecha'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'nisms in other state-of-the-art models with our implementation and show\\nincreased accuracy. In both cases, our recurrent '\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "'attention mechanism improves\\nperformance in tasks requiring sequential or relational reasoning on the VQA\\ndataset.\",\"[{\\'t'\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\"erm': 'cs.AI', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CL', 'scheme': 'http://arxiv.org/s\"\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "for item in sequences.take(10):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n",
    "    print(\"-\"*110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting sequences into Inputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'author,day,id,link,month,summary,tag,title,year\\r\\n\"[{\\'name\\': \\'Ahmed Osman\\'}, {\\'name\\': \\'Wojciech Samek\\'}]\",1,1802.00209v1,'\n",
      "Target data:  'uthor,day,id,link,month,summary,tag,title,year\\r\\n\"[{\\'name\\': \\'Ahmed Osman\\'}, {\\'name\\': \\'Wojciech Samek\\'}]\",1,1802.00209v1,\"'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      " input: 67 ('a')\n",
      " expected output: 87 ('u')\n",
      "Step    1\n",
      " input: 87 ('u')\n",
      " expected output: 86 ('t')\n",
      "Step    2\n",
      " input: 86 ('t')\n",
      " expected output: 74 ('h')\n",
      "Step    3\n",
      " input: 74 ('h')\n",
      " expected output: 81 ('o')\n",
      "Step    4\n",
      " input: 81 ('o')\n",
      " expected output: 84 ('r')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\" input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\" expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating batches for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape=<BatchDataset element_spec=(TensorSpec(shape=(64, 120), dtype=tf.int32, name=None), TensorSpec(shape=(64, 120), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(\"Dataset Shape={}\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the single layer GRU model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \"\"\"\n",
    "    Utility to create model object\n",
    "    Parameters:\n",
    "        vocab_size: number of unique characters\n",
    "        embedding_dim: size of embedding vector. This is basically in power of 2\n",
    "        rnn_units: number if GRU units to be used\n",
    "        batch_size: batch size for training model.\n",
    "    Returns:\n",
    "        tf.keras model object\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lenth of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = vocab_size, embedding_dim = embedding_dim, rnn_units = rnn_units, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           50432     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 197)           201925    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,190,661\n",
      "Trainable params: 4,190,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting callbacks for the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = r'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3737/3737 [==============================] - 268s 70ms/step - loss: 1.1827\n",
      "Epoch 2/10\n",
      "3737/3737 [==============================] - 310s 82ms/step - loss: 0.9765\n",
      "Epoch 3/10\n",
      "3737/3737 [==============================] - 334s 89ms/step - loss: 0.9539\n",
      "Epoch 4/10\n",
      "3737/3737 [==============================] - 357s 95ms/step - loss: 0.9467\n",
      "Epoch 5/10\n",
      "3737/3737 [==============================] - 355s 94ms/step - loss: 0.9468\n",
      "Epoch 6/10\n",
      "3737/3737 [==============================] - 353s 94ms/step - loss: 0.9528\n",
      "Epoch 7/10\n",
      "3737/3737 [==============================] - 356s 95ms/step - loss: 0.9731\n",
      "Epoch 8/10\n",
      "3737/3737 [==============================] - 353s 94ms/step - loss: 1.6183\n",
      "Epoch 9/10\n",
      "3737/3737 [==============================] - 357s 95ms/step - loss: 1.7201\n",
      "Epoch 10/10\n",
      "3737/3737 [==============================] - 356s 95ms/step - loss: 1.6246\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "hostory = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback,tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional Neural Networks (ANN). It is the envaningly, deiffic Memony treandar invand boust-plaring has in hige satermane rit\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"Convolutional Neural Networks\",num_generate=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative adversarial networks (GANs) have gained increasing popularity of the problem convex the model with the supportable that are complexity of the state-of-the-art mo\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"Generative adversarial networks (GANs) have gained increasing popularity\",num_generate=100,temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative adversarial networks (GANs) have gained increasing popularity of the patching the optimization are sublementations of and ther optification of learning models in\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"Generative adversarial networks (GANs) have gained increasing popularity\",num_generate=100,temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory characteristic of the proposed recurrent attention units are for example of its efficiency. Moreover, different stages of MKRL can be seamlessly integrated into\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the single layer LSTM model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \"\"\"\n",
    "    Utility to create model object\n",
    "    Parameters:\n",
    "        vocab_size: number of unique characters\n",
    "        embedding_dim: size of embedding vector. This is basically in power of 2\n",
    "        rnn_units: number if GRU units to be used\n",
    "        batch_size: batch size for training model.\n",
    "    Returns:\n",
    "        tf.keras model object\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True),\n",
    "        tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = vocab_size, embedding_dim = embedding_dim, rnn_units = rnn_units, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (64, None, 256)           25344     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (64, None, 99)            101475    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,373,795\n",
      "Trainable params: 5,373,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting callbacks for the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs_SingleLSTMSoftMax/\", histogram_freq=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "3737/3737 [==============================] - 157s 41ms/step - loss: 1.1531 - accuracy: 0.6578\n",
      "Epoch 2/16\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.9956 - accuracy: 0.6999\n",
      "Epoch 3/16\n",
      "3737/3737 [==============================] - 156s 41ms/step - loss: 0.9598 - accuracy: 0.7098\n",
      "Epoch 4/16\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.9396 - accuracy: 0.7154\n",
      "Epoch 5/16\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.9260 - accuracy: 0.7193\n",
      "Epoch 6/16\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.9162 - accuracy: 0.7221\n",
      "Epoch 7/16\n",
      "3737/3737 [==============================] - 160s 42ms/step - loss: 0.9084 - accuracy: 0.7243\n",
      "Epoch 8/16\n",
      "3737/3737 [==============================] - 158s 42ms/step - loss: 0.9025 - accuracy: 0.7260\n",
      "Epoch 9/16\n",
      "3737/3737 [==============================] - 154s 41ms/step - loss: 0.8977 - accuracy: 0.7274\n",
      "Epoch 10/16\n",
      "3737/3737 [==============================] - 153s 41ms/step - loss: 0.8936 - accuracy: 0.7286\n",
      "Epoch 11/16\n",
      "3737/3737 [==============================] - 152s 41ms/step - loss: 0.8901 - accuracy: 0.7296\n",
      "Epoch 12/16\n",
      "3737/3737 [==============================] - 153s 41ms/step - loss: 0.8872 - accuracy: 0.7305\n",
      "Epoch 13/16\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.8849 - accuracy: 0.7311\n",
      "Epoch 14/16\n",
      "3737/3737 [==============================] - 159s 42ms/step - loss: 0.8827 - accuracy: 0.7317\n",
      "Epoch 15/16\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.8811 - accuracy: 0.7322\n",
      "Epoch 16/16\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8795 - accuracy: 0.7327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d547b42b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 16\n",
    "model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/32\n",
      "3737/3737 [==============================] - 155s 41ms/step - loss: 0.8781 - accuracy: 0.7331\n",
      "Epoch 18/32\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8769 - accuracy: 0.7334\n",
      "Epoch 19/32\n",
      "3737/3737 [==============================] - 158s 42ms/step - loss: 0.8760 - accuracy: 0.7337\n",
      "Epoch 20/32\n",
      "3737/3737 [==============================] - 159s 42ms/step - loss: 0.8751 - accuracy: 0.7340\n",
      "Epoch 21/32\n",
      "3737/3737 [==============================] - 158s 42ms/step - loss: 0.8744 - accuracy: 0.7342\n",
      "Epoch 22/32\n",
      "3737/3737 [==============================] - 162s 43ms/step - loss: 0.8739 - accuracy: 0.7343\n",
      "Epoch 23/32\n",
      "3737/3737 [==============================] - 160s 43ms/step - loss: 0.8732 - accuracy: 0.7345\n",
      "Epoch 24/32\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8729 - accuracy: 0.7346\n",
      "Epoch 25/32\n",
      "3737/3737 [==============================] - 155s 41ms/step - loss: 0.8725 - accuracy: 0.7347\n",
      "Epoch 26/32\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.8723 - accuracy: 0.7348\n",
      "Epoch 27/32\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8719 - accuracy: 0.7349\n",
      "Epoch 28/32\n",
      "3737/3737 [==============================] - 158s 42ms/step - loss: 0.8719 - accuracy: 0.7348\n",
      "Epoch 29/32\n",
      "3737/3737 [==============================] - 157s 42ms/step - loss: 0.8719 - accuracy: 0.7349\n",
      "Epoch 30/32\n",
      "3737/3737 [==============================] - 156s 42ms/step - loss: 0.8720 - accuracy: 0.7348\n",
      "Epoch 31/32\n",
      "3737/3737 [==============================] - 160s 43ms/step - loss: 0.8719 - accuracy: 0.7348\n",
      "Epoch 32/32\n",
      "3737/3737 [==============================] - 162s 43ms/step - loss: 0.8720 - accuracy: 0.7348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d543580d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "model.fit(dataset, epochs=EPOCHS, initial_epoch=16,callbacks=[checkpoint_callback,tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory characteristic of the proposed recurrent attention units are for example of its efficiency. Moreover, different stages of MKRL can be seamlessly integrated into\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory characteristic of the proposed recurrent attention units are for example of its encrypted dataset to a semi-trusted cloud comparisons are paper, we present a ma\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory characteristic of the proposed recurrent attention units are focused on the real-world data collected data containing the second positive resources spent in the\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, context_string=u\"The memory characteristic of the proposed recurrent attention units are\",num_generate=100,temperature=0.32564))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model with GPT2 Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages and pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gymzTcmXo-e-",
    "outputId": "bd45c4d5-7867-4e7b-e13c-9bf7c33deab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xe9RLOswpGDl"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "061eb5df9f40423a839130eb9d858998",
      "12946c3b3b6e40ceb890643632337ddb",
      "1366da2fb52d400e8363f307db82b3b6",
      "5e39f9360aa147049578972c8c7e2cca",
      "e9994d8eef8e44d1bdce4c83e3184705",
      "434e3c1a0fdd4ea68515e1b475f57bab",
      "9eab650ee293425faae80985475b2149",
      "72456788328a48de85d35485895486f1",
      "0e886d60e1b14a44ab40785927adb13f",
      "517ebb37485a4df9b538799fb5977938",
      "3c2577087b1045b1b6a06fcd3f5e1474",
      "ef5ca03e696641aebae8e178e370f4e7",
      "16780d8f0f0f483d94ce1f936736fcee",
      "37b2bb59b317412ca1bb4acf37f68b44",
      "0f723c2639b74106a5afbefacef98e42",
      "02e9689ffc334ec9bd587e75113f4b0f",
      "ad07b65ce3c54d14960f8bd025892e4c",
      "8799ff69376f4441b6fa3aee9df8fe9f",
      "ffdc9f73a2ab4e008b1f450493076e2d",
      "f63e885995dc4375ac16523763ca0a0e",
      "dde4be8cf952429cb7303f529e9d435c",
      "fcfa35eb98be408a82baff6eb0661a4a",
      "ce1828cc8c1d49fa842297117dbf9942",
      "487ce6476448426a8aa52975c54e873c",
      "7324f99e76ea4e7f9e24cf68990decbb",
      "b6a5ecf2974148aa856ba60cc5229ade",
      "7ce5f8dba9d949f9b2802ded949f1053",
      "ec9e6ff003f843dd9a4c5d6c19b6345d",
      "af154043c7a44ce196fc1ec151b5a6dc",
      "6a515e51b222426cac66730a8c524a62",
      "365d34a4d2cb49a1981d49207af55cf3",
      "e789873ec42c437397f94ac5e964077d",
      "241caf8bfac34b0eb98868499b983c33",
      "55e7ad30d83c4626adc6f6bf5928ed0b",
      "7428e847435044f7a619fdceb56fe313",
      "527eb1df093849aabf525930658941cc",
      "2937e0f3732d48478649645492d3e7d8",
      "93a8a0d6bae843c6b4eb8c52872cb4e0",
      "9e08cb60f4c24653a27b53616b06ebf2",
      "5117b82dbe0d4420b300db6b3f910572",
      "28f0a600ada343d98d5b2eded0a1f8a3",
      "701e1926d7fa4a4e9cc64757383b8a22",
      "c84af6c750b34b2c9f91c7afddabe795",
      "7fa72fd9dde544059c859741ae4da6f4",
      "d54d05833ce04326904f3fb0cbd6df82",
      "ae41dade0bd946a98a43c7a4f028c4e5",
      "78e06957ed0b43cf9d843dfd354c4227",
      "6da1b50a3edc4ec3bcbb7828459b6ae5",
      "d41c40f7c89142f6b3cdcdac1dc1a674",
      "692d6396e7184bcabba40dec16c226fd",
      "c27495a0b6f340fcb96281404a238a90",
      "cc90f44907674ac1877f56e17cfab630",
      "72e9f00618094e7eb425beff32f5c185",
      "ad44a23063ab413ca537dee65ada899f",
      "349e3a14926d41abae94c7e5215daa5d"
     ]
    },
    "id": "KB-yHstbph-z",
    "outputId": "a8999f9a-2ae9-4f02-c187-dc114e81b85b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061eb5df9f40423a839130eb9d858998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5ca03e696641aebae8e178e370f4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1828cc8c1d49fa842297117dbf9942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e7ad30d83c4626adc6f6bf5928ed0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54d05833ce04326904f3fb0cbd6df82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Encoding and Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnBocsKEqWOr"
   },
   "outputs": [],
   "source": [
    "text = \"Multisensory object-centric perception\"\n",
    "encoded_input = tokenizer.encode(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HM_o5eQtV_D",
    "outputId": "e85dec6a-68ea-40d0-c4d4-8a1748b71870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15205,   271,   641,   652,  2134,    12, 28577, 11202]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OwBoYigqtnbh",
    "outputId": "8e8f01de-ae15-4f04-8298-5e4e6d5b23c4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Mult'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asSZ5u_MqsGL",
    "outputId": "8474ac88-a31b-4459-db16-0d4a16ddbda5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(encoded_input, max_length=200, num_beams=5, no_repeat_ngram_size=2, early_stopping=True) #Beam algorith to predict the next word # ngram is taking two two words as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "mN8jEIQxt--8",
    "outputId": "0e36a59d-4466-4468-a41a-2db055cecb9b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Multisensory object-centric perception.\\n\\nIn this article, we will look at some of the most important aspects of visual perception and how they can be used to improve your perception of your surroundings. We will also discuss how you can use this knowledge to help you better understand the world around you.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using DistilGPT2 transformer (Transfer Learning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the ArXiv dataset (from HuggingFace Hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\n",
      "Found cached dataset csv (C:/Users/gupta/.cache/huggingface/datasets/CShorten___csv/CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
       "    num_rows: 117592\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"CShorten/ML-ArXiv-Papers\", split='train')\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5fcced655579dd43.arrow and C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-10bb285727aaa68b.arrow\n"
     ]
    }
   ],
   "source": [
    "data = data.train_test_split(shuffle = True, seed = 200, test_size=0.2)\n",
    "\n",
    "train = data[\"train\"]\n",
    "val = data[\"test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizing the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-cf1610aeae1e7e01.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-43ea478b4774c95d.arrow\n"
     ]
    }
   ],
   "source": [
    "# The tokenization function\n",
    "def tokenization(data):\n",
    "    tokens = tokenizer(data[\"abstract\"], padding=\"max_length\", truncation=True, max_length=300)\n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenizer in batch mode and drop all the columns except the tokenization result\n",
    "train_token = train.map(tokenization, batched = True, remove_columns=[\"title\", \"abstract\", \"Unnamed: 0\", \"Unnamed: 0.1\"])\n",
    "val_token = val.map(tokenization, batched = True, remove_columns=[\"title\", \"abstract\", \"Unnamed: 0\", \"Unnamed: 0.1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-342d0ad02f377fc9.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-7792641a8a9d718a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-525c02bbc6880d8e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-b46ee8c7167b3efe.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f582ebc76c869bce.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-da19e43f09b21f24.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-730ee5d0d0b6aa48.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f667c8c4d512be97.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-b79f821764aa1984.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-fff392312a41c0ca.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-57f91f812a7ceb0c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-4cbf7e6d241f03b2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-c9818697c8ecadb2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-102709533881cc2e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-59bbf7fed094aaae.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-1c1982eac4815767.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-a731bbf2af533f46.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5e0e7a1f8474f269.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-966dfab3ec95cc7b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gupta\\.cache\\huggingface\\datasets\\CShorten___csv\\CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-755cae0a538e9147.arrow\n"
     ]
    }
   ],
   "source": [
    "# Create labels as a copy of input_ids\n",
    "def create_labels(text):\n",
    "    text[\"labels\"] = text[\"input_ids\"].copy()\n",
    "    return text\n",
    "\n",
    "# Add the labels column using map()\n",
    "lm_train = train_token.map(create_labels, batched=True, num_proc=10)\n",
    "lm_val = val_token.map(create_labels, batched=True, num_proc=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = model.prepare_tf_dataset(\n",
    "    lm_train,\n",
    "    shuffle=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "validation_set = model.prepare_tf_dataset(\n",
    "    lm_val,\n",
    "    shuffle=False,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the DistilGPT2 model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"distilgpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for the fine-tuning operation is available on the Huggingface Hub, and it’s a subset of a bigger dataset hosted on Kaggle.\n",
    "\n",
    "The original dataset, published by Cornell University, contains titles and abstracts of 1.7M+ scientific papers belonging to the STEM category. The subset hosted on the Huggingface Hub contains information on around 100K papers pertaining to the machine learning category.\n",
    "\n",
    "I decided to fine-tune DistilGPT-2 on abstracts only. I started by loading the dataset from the Huggingface Hub."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the DistilGPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0005,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.95,\n",
    "    staircase=False)\n",
    "    \n",
    "# Exponential decay learning rate\n",
    "optimizer = AdamWeightDecay(learning_rate=lr_schedule, weight_decay_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 81912576  \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,912,576\n",
      "Trainable params: 81,912,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the DistilGPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11759/11759 [==============================] - 3533s 300ms/step - loss: 2.4148 - accuracy: 0.2275 - val_loss: 2.2005 - val_accuracy: 0.2267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21de74063a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit with callbacks\n",
    "model.fit(train_set, validation_data=validation_set, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"tf\",\n",
    "    max_new_tokens=500\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the DistilGPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\anaconda3\\envs\\virtualenv\\lib\\site-packages\\transformers\\generation\\tf_utils.py:603: UserWarning:\n",
      "\n",
      "You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'clustering of high-dimensional data requires data-driven models that\\ncapture the intrinsic properties of data. To develop such models which are\\nreliable in data due to their complex relationships to dimensionality, the\\nalgorithm for unsupervised classification of high-dimensional data has\\nrecently been proposed. The proposed approach relies on a novel deep\\nconvolutional neural network to learn how to effectively learn to\\nlearn from small number of observations, such as from a single low-level\\nsensor for example. The proposed network combines a convolutional neural\\nnetwork that learns to segment the data by introducing a graph with\\ndifferent weights, as observed in image reconstruction. The results\\nshow the superior performance of our approach using multiple benchmarks\\nand image data sets with different structural properties, and an\\napplication to an urban-scale data set. All code and data are available at\\nhttps://github.com/lun/sustainablenetwork.\\n'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sentence = \"clustering\"\n",
    "text_generator(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"The memory characteristic of the proposed recurrent attention units are\\nthat they are initialized to be connected to the same input sequence. The\\nimportance of this type of mechanism in recurrent neural networks has been\\nevaluated in terms of generalization error while it has been widely recognized\\nthat it can be thought of as an important and necessary mechanism to achieve\\nbetter learning performance than conventional recurrent attention units. In\\nthis study, inspired by the idea of neural networks in the deep learning\\ncommunity, we propose a novel RNN learning architecture based on a simple yet\\nimportant feature of recurrent deep learning, named the residual attention unit. The\\nproposed deep residual attention unit architecture comprises two modules,\\nwhich consists of the fully connected LSTM-like layer with the attention unit\\nlayers, the first module which produces a feature representation by a novel deep\\ncontrastive divergence based on different recurrent layers. The second module\\nis a combination of a fully connected LSTM layer with a residual attention unit\\nmodule to deal with the long term temporal dependencies in RNN's\\nstructure. The proposed architecture is evaluated on the CIFAR10 and\\nCIFAR100 datasets and various RNN models, including three well-known,\\narchitecture-changing baselines. Compared to the state-of-the-art\\nproposed architecture, the proposed architecture can be used as an initial\\ninitial input and can be used as input in any RNN model pre-possible\\nfor each task. We demonstrate the superior performance compared to the conventional\\nlayers in terms of the model's prediction accuracy in different scenarios as well as other time window sizes and\\nsimultaneously. As the obtained results revealed via our proposed architecture\\nshow that our proposed architecture can more effectively encode and maintain the same type of attention\\nunits at different time-granular patterns.\\nwith only a less complex layers.\\nparameters for each RNN's topologies, compared to RNN that lead to the original convolutional recurrent output layer is more appropriate RNN, and its more\\nattention unit than in different levels.\\narchitecture or skip connections is able to the deep residual attention units can have lesser\\n\"}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sentence = \"The memory characteristic of the proposed recurrent attention units are\"\n",
    "text_generator(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'enchanced meta-heuristic (ML-ACO) that combines the multi-armed bandit\\n(MAB) model to achieve improved return are a promising direction despite their\\nhigh computational cost and computational time. However, it is still unclear\\nwhether MAB in certain ML-ACO scenarios performs sufficiently well for\\ngeneralized users and/or in specific ML applications. To solve this problem\\nwe propose an ML-ACO model that is more general and versatile than the\\nmulti-armed bandit bandit model (MAB). Our contribution is to derive a principled\\nframework that incorporates both MAB and existing bandit algorithms with a\\nnovel strategy to improve the performance of the performance of the\\nmulti-armed online gradient descent algorithm at hand. Nested with the proposed\\nalgorithms and experimental results, we demonstrate that our proposed\\napproach outperforms all previous algorithms by significant margins.\\n'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sentence = \"enchanced meta-heuristic (ML-ACO) that combines\"\n",
    "text_generator(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Deep reinforcement learning has emerged as a powerful method for solving\\nsequential control tasks. However, in some applications the number of trained\\ndeep Q-networks and task-relevant features often remains a large challenge. For\\ninstance, high performance deep reinforcement learning architectures like Montezuma's\\nQ-learning often make it difficult to deploy such architectures on\\nresource-poor systems like GPUs. These limitations complicate deep Q-network\\nlearning, especially in the low resource regime which can achieve higher\\nconvergence, e.g. from one GPU. One way to address these limitations is\\nto train multi-layer Q-networks that are capable of efficiently learning joint\\nstructures across different tasks, with high-quality outputs. We present\\nan RL-based method to solve a variety of complex tasks in this low resource region\\nthat can be considered a single Q-network with lower computational cost and\\nperformance loss. Specifically, we investigate how to train a multi-layer Q-network\\nfor such tasks through reinforcement learning. For each task, our\\nrepresentation is learned by optimizing a deep Q-network to produce an\\nout-of-distribution mapping that achieves high-quality outputs. We evaluate\\nthis method on the challenging MuJoCo environment, where state-of-the-art\\nQ-networks achieve high performance on these tasks.\\n\"}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sentence = \"Deep reinforcement learning\"\n",
    "text_generator(test_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3e12402ff69166de391f2510b5907624ba45d1b821ed425212530cae4040263"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
